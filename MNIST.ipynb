{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ll-gj5OCVrL5"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qjYg-0MfTpg",
        "outputId": "f20a57e0-5697-4eea-fda8-ce17cdbcba85"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ],
      "source": [
        "mnist = fetch_openml('mnist_784')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tNj7GbiA4vkR"
      },
      "outputs": [],
      "source": [
        "# test Data to be used\n",
        "x_testData = mnist.data[:5000]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zTet43Y542zQ"
      },
      "outputs": [],
      "source": [
        "trainingData = mnist.data[5001:6001]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "X-IalO-Q4z5f"
      },
      "outputs": [],
      "source": [
        "# Target Labels [0-9]\n",
        "y_labelData = mnist.target[:5000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4fIdHiYa8IIK"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([687,  35, 969, 209, 865, 237, 362, 590, 871, 411, 925, 709, 382,\n",
              "       837, 206, 159, 735, 537, 422,  66, 587, 769, 973, 790, 819, 933,\n",
              "       602,  96,   0,  65, 940, 496, 857,  59, 111, 978, 359,  38, 684,\n",
              "       290, 903, 679, 452, 563,  24, 324, 527, 855, 665, 869,  12, 874,\n",
              "       786, 431, 629,  55, 756, 549, 690, 830, 147, 961, 751,  27, 985,\n",
              "       847, 779, 353, 923, 200, 293, 975, 223, 345, 639, 416, 332, 160,\n",
              "       573, 567, 724, 897,  79,  40,  49, 677, 389, 142,  97, 653, 955,\n",
              "       659,  86, 337, 859, 870, 771, 239, 340, 737, 780, 371, 685, 561,\n",
              "       767, 774, 233, 446, 498, 402, 715, 695,   2, 649, 298, 490,  25,\n",
              "       597, 817, 525, 546, 241, 792, 492, 783,  20,  41, 585,  58,  57,\n",
              "       785, 707, 752, 113, 255, 196, 922, 464, 770, 910,  21, 103,  10,\n",
              "       760, 965, 895, 391, 503, 555, 741, 601, 213, 291, 744, 260, 335,\n",
              "       949, 700, 268, 139,  81, 551, 825,  11, 189, 269, 936, 342, 778,\n",
              "       938,  19, 675, 439, 140,   3, 187, 875, 208, 231, 731, 185, 505,\n",
              "       920, 295, 839, 256, 336, 647, 463, 599, 423, 713, 581, 648, 935,\n",
              "       755,  36, 592, 861,  29, 918, 832, 849, 122, 250, 989,  53, 515,\n",
              "       710, 203, 287, 777, 470, 280, 451, 813,  99, 663, 177, 569, 519,\n",
              "       143, 279, 277, 510, 609, 303, 929,  23, 881, 765, 497, 289,  56,\n",
              "       863, 946, 271, 175, 127, 578, 900, 491, 475, 746, 745,   5, 183,\n",
              "       759, 251, 276, 232, 427, 242, 461, 455, 788, 753, 447, 367, 425,\n",
              "        42, 991,  22, 876, 689, 218, 823, 726, 486, 173, 253, 430, 120,\n",
              "        89, 982, 126, 432, 145, 499, 465, 773, 440, 346, 529, 338, 912,\n",
              "       654, 766, 928, 845, 916, 909, 483, 394, 457, 261, 205, 506, 637,\n",
              "       762, 539, 797, 775, 931, 738,  30, 543, 833, 932,  34, 533, 179,\n",
              "       826, 721, 327, 712, 210, 198, 557, 948, 184, 566, 879, 905, 509,\n",
              "       834, 666, 805, 180, 627, 135, 577, 877, 109, 618, 606, 652, 530,\n",
              "       596, 704, 199, 172, 600, 568, 763, 131, 395,  88, 138, 772, 485,\n",
              "       678, 488, 598, 829, 816, 481, 782, 963,   4, 634, 252, 305,  95,\n",
              "       642, 953, 681, 838, 761, 329, 222, 917, 545,   7, 123,  82, 493,\n",
              "       904, 322, 798, 924, 703, 993, 984, 611, 101, 541, 705, 804,  13,\n",
              "       815, 182, 207, 999, 699, 764, 326, 414, 671, 926, 433, 808, 560,\n",
              "       983,  72, 412, 162, 211, 574, 841, 407, 911, 848, 141, 615, 453,\n",
              "       167, 836, 570, 270,  54, 680, 728, 112, 657, 893, 890, 619, 482,\n",
              "       882, 514,  50, 301,  14, 616, 962, 418, 594, 309, 768, 892, 236,\n",
              "       114, 413, 674,  74, 478, 263, 998, 224,  68, 730, 902, 575, 284,\n",
              "       944, 996, 404, 858, 952,  78, 204, 215, 507, 354, 802, 937, 959,\n",
              "       862, 878, 517, 896, 102, 550,  87, 656, 238, 282, 927, 450, 374,\n",
              "       169, 325, 692, 275, 886, 390, 943, 887, 956, 163, 518, 516, 244,\n",
              "       997, 743, 521, 228, 784, 812, 995, 694, 278, 462, 234, 115,  93,\n",
              "       748, 867, 542, 701,  77, 403,  32, 274, 791, 299,  46, 466, 471,\n",
              "       624, 864, 793, 513, 880, 736, 930, 445, 719, 377, 583, 283, 891,\n",
              "       248, 538, 323, 554, 273,  85, 121,   8, 979,  45, 623, 941, 754,\n",
              "         1, 914, 214,  37, 144, 217, 484, 398,  47, 155, 526, 393, 401,\n",
              "       921, 149, 381, 789, 757, 449, 655, 467, 523, 716, 682, 593, 259,\n",
              "       438, 351, 630, 106,  39, 603,  62, 868, 202, 650, 669, 225, 434,\n",
              "       350, 976, 987, 522, 130, 722, 636, 378,  69, 818, 118, 428, 552,\n",
              "       564,  80, 811, 444, 266, 442, 580, 494, 100, 604, 534, 176, 605,\n",
              "        94, 806, 262, 220, 883, 307,  48, 348, 188, 219, 117, 740, 370,\n",
              "       419, 572, 850, 358, 828,  52, 355, 108, 285, 856, 621, 443, 668,\n",
              "       620, 157, 556, 758, 480, 316, 718,  98, 742, 888, 321, 532, 426,\n",
              "       366, 136, 643,   6, 281, 410, 369, 304, 415, 686, 821, 229, 129,\n",
              "       360, 148, 300, 387, 986, 942, 852, 628, 476, 265, 357, 854, 151,\n",
              "       576, 424, 749, 625, 308, 608, 302, 124, 536,  90, 820, 720, 696,\n",
              "       898, 313, 380, 723, 520, 400, 306, 553,  67, 417, 195, 667, 644,\n",
              "       617, 951, 796, 186, 458, 698, 146, 595, 547, 810, 939, 708, 128,\n",
              "       954, 827, 613,  76,  84, 974,  28, 670, 456, 334, 104, 958, 588,\n",
              "       388, 702, 646, 472, 990, 116, 907, 375, 934, 794,  26, 733, 846,\n",
              "       192, 384, 582, 436, 612, 693, 571, 824, 178, 166,  91,  92, 631,\n",
              "       193, 622, 814, 734, 168, 591, 840, 873, 799, 776, 967, 489, 132,\n",
              "       161, 368, 328, 165, 288, 866, 361, 822, 589, 310, 194, 558, 540,\n",
              "       164, 495, 254, 851, 243, 487, 171, 133, 420, 137, 658, 363, 156,\n",
              "       469,  44, 843, 885, 230, 860, 945, 399, 110, 662, 614, 105, 441,\n",
              "       341, 201, 889, 134, 154, 212, 853, 311, 835, 331, 297, 915, 500,\n",
              "       727, 950, 479, 807, 717, 787,  70, 356, 272, 957, 257,  43, 333,\n",
              "       872, 349,  16, 373, 641, 249, 544, 312, 800,  75, 454, 508, 383,\n",
              "       264, 347, 448,  60, 294, 330, 502, 964,  33, 664, 966, 562,  61,\n",
              "       504,  31, 459, 626, 977, 437, 739, 352, 405,  18, 795, 610, 247,\n",
              "       548, 119, 632, 906, 725, 528, 842, 531, 235, 711, 197, 501, 579,\n",
              "       314, 406, 913,  17, 947, 435,  15, 732, 365, 809, 221, 191, 240,\n",
              "       899, 379, 691, 296, 988, 216, 409, 661,  73, 750, 638,  83, 706,\n",
              "       801, 831, 158, 511, 512, 408, 673,  64, 286, 640, 107,   9, 972,\n",
              "       651, 803, 174, 170, 460, 960, 688, 586, 181, 901, 565, 385, 559,\n",
              "       645, 844, 474, 477, 473, 919, 524, 372, 535, 364, 150, 676, 747,\n",
              "       315, 397, 635, 152, 672, 317, 421, 339, 258, 343, 970, 584, 994,\n",
              "       396, 607, 318, 344,  71, 292, 376,  51, 190, 246, 392, 992, 968,\n",
              "       227, 683, 884, 714, 319, 660, 125, 980, 429, 781, 468, 894,  63,\n",
              "       226, 386, 153, 729, 320, 908, 267, 245, 697, 633, 971, 981])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "distance = euclidean_distances(x_testData, trainingData)\n",
        "sorted_distance = np.argsort(distance, axis=1) # set axis=1 to specify sorting distances along the rows\n",
        "\n",
        "test_img_index = 0 # set a random index to see the distance from 1 test img to the others\n",
        "distance[test_img_index] # represents the dist from a specific test img to all other training images\n",
        "sorted_distance[test_img_index] # represents the index of the training images that are closest to the test img based on distances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-hqh7p10jVvC"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "FUNCTION - KNN(x, y, dist, k)\n",
        "\n",
        "RETURNS - an array of predicted labels\n",
        "'''\n",
        "def KNN(x, y, dist, k):\n",
        "  num_test = len(dist)\n",
        "  predicted_labels = [] # represents the predicted class for each test image\n",
        "  for i in range(num_test):\n",
        "    neighbors = dist[i, :k]\n",
        "    labels = y[neighbors]\n",
        "    predicted_labels.append(predict(labels, k))\n",
        "  return predicted_labels\n",
        "\n",
        "\n",
        "'''\n",
        "FUNCTION - predict(nLabels, k)\n",
        "\n",
        "Takes in the labels of KNN && counts the occurences of each label\n",
        "and finds the label with the highest count && returns the most frequently \n",
        "as the predicted label\n",
        "'''\n",
        "def predict(nLabels, k):\n",
        "    unique_labels, counts = np.unique(nLabels, return_counts=True)\n",
        "    majority_label = unique_labels[np.argmax(counts)]  \n",
        "    return predict\n",
        "\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvXV-8OSs-SP",
        "outputId": "342e60ee-d9ba-4efd-f23e-7cade447d67d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<function KNN at 0x147d71bd0>\n"
          ]
        }
      ],
      "source": [
        "KNN(x_testData, y_labelData, sorted_distance, 5)\n",
        "print(KNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ezaS3b3MqTeT"
      },
      "outputs": [],
      "source": [
        "def get_accuracy(x, y, test_size=0.2, max_k=50, random_state=42):\n",
        "    accuracy = []\n",
        "    X_train, X_val, y_train, y_val = train_test_split(x, y, test_size=test_size, random_state=random_state)\n",
        "    for k in range(1, max_k + 1):\n",
        "        knn = KNeighborsClassifier(n_neighbors=k)\n",
        "        knn.fit(X_train, y_train)\n",
        "        y_pred = knn.predict(X_val)\n",
        "        accuracy_score_val = accuracy_score(y_val, y_pred)\n",
        "        accuracy.append(accuracy_score_val)\n",
        "        print(\"K =\", k, \"Accuracy:\", accuracy_score_val)\n",
        "    return accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Hkw2XUQuRC3",
        "outputId": "95791404-d06d-4dc6-ccf7-619201396908"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K = 1 Accuracy: 0.946\n",
            "K = 2 Accuracy: 0.932\n",
            "K = 3 Accuracy: 0.942\n",
            "K = 4 Accuracy: 0.942\n",
            "K = 5 Accuracy: 0.941\n",
            "K = 6 Accuracy: 0.935\n",
            "K = 7 Accuracy: 0.934\n",
            "K = 8 Accuracy: 0.935\n",
            "K = 9 Accuracy: 0.93\n",
            "K = 10 Accuracy: 0.93\n",
            "K = 11 Accuracy: 0.931\n",
            "K = 12 Accuracy: 0.928\n",
            "K = 13 Accuracy: 0.922\n",
            "K = 14 Accuracy: 0.924\n",
            "K = 15 Accuracy: 0.921\n",
            "K = 16 Accuracy: 0.923\n",
            "K = 17 Accuracy: 0.925\n",
            "K = 18 Accuracy: 0.922\n",
            "K = 19 Accuracy: 0.922\n",
            "K = 20 Accuracy: 0.92\n",
            "K = 21 Accuracy: 0.918\n",
            "K = 22 Accuracy: 0.917\n",
            "K = 23 Accuracy: 0.917\n",
            "K = 24 Accuracy: 0.917\n",
            "K = 25 Accuracy: 0.915\n",
            "K = 26 Accuracy: 0.914\n",
            "K = 27 Accuracy: 0.914\n",
            "K = 28 Accuracy: 0.915\n",
            "K = 29 Accuracy: 0.913\n",
            "K = 30 Accuracy: 0.913\n",
            "K = 31 Accuracy: 0.911\n",
            "K = 32 Accuracy: 0.912\n",
            "K = 33 Accuracy: 0.911\n",
            "K = 34 Accuracy: 0.913\n",
            "K = 35 Accuracy: 0.912\n",
            "K = 36 Accuracy: 0.911\n",
            "K = 37 Accuracy: 0.911\n",
            "K = 38 Accuracy: 0.905\n",
            "K = 39 Accuracy: 0.906\n",
            "K = 40 Accuracy: 0.901\n",
            "K = 41 Accuracy: 0.901\n",
            "K = 42 Accuracy: 0.901\n",
            "K = 43 Accuracy: 0.898\n",
            "K = 44 Accuracy: 0.901\n",
            "K = 45 Accuracy: 0.899\n",
            "K = 46 Accuracy: 0.901\n",
            "K = 47 Accuracy: 0.9\n",
            "K = 48 Accuracy: 0.898\n",
            "K = 49 Accuracy: 0.898\n",
            "K = 50 Accuracy: 0.897\n"
          ]
        }
      ],
      "source": [
        "# output the accuracy based on K\n",
        "\n",
        "accuracyV = get_accuracy(x_testData, y_labelData)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
