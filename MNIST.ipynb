{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Ll-gj5OCVrL5"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = fetch_openml('mnist_784')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qjYg-0MfTpg",
        "outputId": "f20a57e0-5697-4eea-fda8-ce17cdbcba85"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test Data to be used\n",
        "x_testData = mnist.data[:5000]\n"
      ],
      "metadata": {
        "id": "tNj7GbiA4vkR"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainingData = mnist.data[5001:6001]"
      ],
      "metadata": {
        "id": "zTet43Y542zQ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Target Labels [0-9]\n",
        "y_labelData = mnist.target[:5000]"
      ],
      "metadata": {
        "id": "X-IalO-Q4z5f"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distance = euclidean_distances(x_testData, trainingData)\n",
        "sorted_distance = np.argsort(distance, axis=1) # set axis=1 to specify sorting distances along the rows\n",
        "\n",
        "test_img_index = 0 # set a random index to see the distance from 1 test img to the others\n",
        "distance[test_img_index] # represents the dist from a specific test img to all other training images\n",
        "sorted_distance[test_img_index] # represents the index of the training images that are closest to the test img based on distances\n",
        "\n",
        "# print(\"test dist 0\", distance[0]) \n",
        "# print(\"test index 0\", sorted_distance[0])\n",
        "\n"
      ],
      "metadata": {
        "id": "4fIdHiYa8IIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "FUNCTION - KNN(x, y, dist, k)\n",
        "\n",
        "RETURNS - an array of predicted labels\n",
        "'''\n",
        "def KNN(x, y, dist, k):\n",
        "  num_test = len(dist)\n",
        "  predicted_labels = [] # represents the predicted class for each test image\n",
        "  for i in range(num_test):\n",
        "    neighbors = dist[i, :k]\n",
        "    labels = y[neighbors]\n",
        "    predicted_labels.append(predict(labels, k))\n",
        "  return predicted_labels\n",
        "\n",
        "\n",
        "'''\n",
        "FUNCTION - majority_voting(nLabels, k)\n",
        "\n",
        "Takes in the labels of KNN && counts the occurences of each label\n",
        "and finds the label with the highest count && returns the most frequently \n",
        "as the predicted label\n",
        "'''\n",
        "def predict(nLabels, k):\n",
        "    unique_labels, counts = np.unique(nLabels, return_counts=True)\n",
        "    majority_label = unique_labels[np.argmax(counts)]  \n",
        "    return predict\n",
        "\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "-hqh7p10jVvC"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "KNN(x_testData, y_labelData, sorted_distance, 5)\n",
        "print(KNN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvXV-8OSs-SP",
        "outputId": "342e60ee-d9ba-4efd-f23e-7cade447d67d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<function KNN at 0x7fd6e383cf70>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def get_accuracy(x, y, test_size=0.2, max_k=50, random_state=42):\n",
        "    accuracy = []\n",
        "    X_train, X_val, y_train, y_val = train_test_split(x, y, test_size=test_size, random_state=random_state)\n",
        "    for k in range(1, max_k + 1):\n",
        "        knn = KNeighborsClassifier(n_neighbors=k)\n",
        "        knn.fit(X_train, y_train)\n",
        "        y_pred = knn.predict(X_val)\n",
        "        accuracy_score_val = accuracy_score(y_val, y_pred)\n",
        "        accuracy.append(accuracy_score_val)\n",
        "    optimal_k = accuracy.index(max(accuracy)) + 1\n",
        "    return accuracy, optimal_k\n",
        "\n"
      ],
      "metadata": {
        "id": "ezaS3b3MqTeT"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy, optimal_k = get_accuracy(x_testData, y_labelData, test_size=0.2, max_k=50, random_state=42)\n",
        "print(\"Accuracy for different k values:\", accuracy)\n",
        "print(\"Optimal k value with highest accuracy:\", optimal_k)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Hkw2XUQuRC3",
        "outputId": "95791404-d06d-4dc6-ccf7-619201396908"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for different k values: [0.946, 0.932, 0.942, 0.942, 0.941, 0.935, 0.934, 0.935, 0.93, 0.93, 0.931, 0.928, 0.922, 0.924, 0.921, 0.923, 0.925, 0.922, 0.922, 0.92, 0.918, 0.917, 0.917, 0.917, 0.915, 0.914, 0.914, 0.915, 0.913, 0.913, 0.911, 0.912, 0.911, 0.913, 0.912, 0.911, 0.911, 0.905, 0.906, 0.901, 0.901, 0.901, 0.898, 0.901, 0.899, 0.901, 0.9, 0.898, 0.898, 0.897]\n",
            "Optimal k value with highest accuracy: 1\n"
          ]
        }
      ]
    }
  ]
}